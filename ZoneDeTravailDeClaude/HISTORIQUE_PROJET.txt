================================================================================
           HISTORIQUE DU PROJET - SIREN Investigation Agent
                     Session du 21 Janvier 2026
================================================================================

1. CONTEXTE INITIAL
-------------------
- Entreprise : SIREN (graphes d'investigation)
- Objectif : Cr√©er un syst√®me multi-agents orchestr√© par LLM (OpenAI)
- Ancien projet : Trop complexe (9 agents, code non fonctionnel)
- Nouveau besoin : Fresh start avec 3 agents seulement

2. ARCHITECTURE CON√áUE
----------------------
Nous avons con√ßu une architecture simplifi√©e :

    Utilisateur (langage naturel)
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     ORCHESTRATEUR (LangGraph)       ‚îÇ
    ‚îÇ                                     ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  ‚îÇPlanificateur‚îÇ ‚îÇPriorisation‚îÇ ‚îÇ  R√©sum√©   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                                     ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
    ‚îÇ  ‚îÇ   Outils IF (D√©terministes)    ‚îÇ‚îÇ
    ‚îÇ  ‚îÇ  lookup, get_neighbors, etc.   ‚îÇ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
      Elasticsearch (SIREN Investigate)

3. FICHIERS CR√â√âS
-----------------
/ZoneDeTravailDeClaude/
‚îú‚îÄ‚îÄ main.py                 ‚Üí Point d'entr√©e CLI
‚îú‚îÄ‚îÄ requirements.txt        ‚Üí D√©pendances Python
‚îú‚îÄ‚îÄ .env                    ‚Üí Configuration (cl√© OpenAI, Elasticsearch)
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ planner.py         ‚Üí Agent Planificateur
‚îÇ   ‚îú‚îÄ‚îÄ prioritizer.py     ‚Üí Agent Priorisation
‚îÇ   ‚îî‚îÄ‚îÄ summarizer.py      ‚Üí Agent R√©sum√©
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ elasticsearch_tools.py ‚Üí Outils IF (foraging)
‚îî‚îÄ‚îÄ core/
    ‚îî‚îÄ‚îÄ orchestrator.py    ‚Üí Orchestrateur LangGraph

4. PROBL√àME RENCONTR√â : BIBLIOTH√àQUE ELASTICSEARCH
--------------------------------------------------
ERREUR INITIALE :
    elasticsearch.ApiError: ApiError(500, 'security_exception', 'Not an SSL request')

DIAGNOSTIC :
- La biblioth√®que Python `elasticsearch` v9.x avait un probl√®me de connexion SSL
- Malgr√© les param√®tres verify_certs=False et ssl_show_warn=False,
  la biblioth√®que envoyait des requ√™tes HTTP au lieu de HTTPS
- Le serveur SIREN Elasticsearch attendait du HTTPS et rejetait les requ√™tes

TEST DE V√âRIFICATION :
- curl -k (avec HTTPS) fonctionnait parfaitement
- La biblioth√®que `requests` fonctionnait aussi
- Seule la biblioth√®que `elasticsearch` posait probl√®me

SOLUTION APPLIQU√âE :
- Remplacement de la biblioth√®que `elasticsearch` par `requests` directement
- Cr√©ation d'une m√©thode _search() qui utilise requests.post() avec verify=False
- R√©sultat : Connexion fonctionnelle !

CODE AVANT (ne fonctionnait pas) :
    from elasticsearch import Elasticsearch
    es = Elasticsearch("https://localhost:9220", verify_certs=False)
    es.search(...)  # ERREUR SSL

CODE APR√àS (fonctionne) :
    import requests
    response = requests.post(url, json=query, auth=auth, verify=False)
    response.json()  # OK !

5. AUTRE BUG CORRIG√â : NoneType dans get_neighbors
--------------------------------------------------
ERREUR :
    TypeError: 'NoneType' object is not iterable

CAUSE :
- Certains documents "investment" n'avaient pas de champ "investors"
- Le code faisait : inv.get("investors", []) mais retournait None au lieu de []

SOLUTION :
- Chang√© en : inv.get("investors") or []
- Cela g√®re le cas o√π le champ est None ou absent

6. TESTS R√âUSSIS
----------------
Requ√™te 1 : "Quels sont les investisseurs de MongoDB?"
‚Üí R√©sultat : MongoDB n'a pas d'investisseurs dans cette base demo

Requ√™te 2 : "Trouve les investisseurs d'Airbnb"
‚Üí R√©sultat : Keith Rabois, Y Combinator

Requ√™te 3 : "Trouve un lien entre Twitter et Airbnb"
‚Üí R√©sultat : 6 investisseurs communs trouv√©s !
   - Ron Conway
   - Tim Ferriss
   - Kleiner Perkins Caufield & Byers
   - T. Rowe Price
   - DFJ Growth
   - Union Square Ventures

7. SERVICES EN ARRI√àRE-PLAN
---------------------------
Elasticsearch et Siren Investigate ont √©t√© lanc√©s en arri√®re-plan.

Pour les arr√™ter :
    pkill -f elasticsearch
    pkill -f investigate

Pour les relancer :
    cd /home/pierre/T√©l√©chargements/siren-platform-demo-data-15.0.0-linux-x86_64/elasticsearch
    ./bin/elasticsearch &

    cd /home/pierre/T√©l√©chargements/siren-platform-demo-data-15.0.0-linux-x86_64/siren-investigate
    ./bin/investigate &

8. LIMITATION D√âCOUVERTE : D√âPASSEMENT DE CONTEXTE
---------------------------------------------------
ERREUR :
    openai.BadRequestError: context_length_exceeded (128068 tokens > 128000 max)

CAUSE :
- Requ√™tes complexes avec filtres temporels peuvent causer des boucles
- Le syst√®me a fait 53 it√©rations avant de d√©passer la limite
- Chaque it√©ration accumule des r√©sultats dans les messages

EXEMPLE QUI √âCHOUE :
    "Quels investisseurs ont investi dans Twitter entre 2008 et 2012?"

EXEMPLES QUI FONCTIONNENT :
    "Trouve les investisseurs d'Airbnb"
    "Trouve un lien entre Twitter et Airbnb"

AM√âLIORATIONS POSSIBLES (pour plus tard) :
- Tronquer les messages anciens pour rester sous la limite (Option 2)
- Ajouter une logique de compression/r√©sum√© interm√©diaire (Option 3)

9. SOLUTION IMPL√âMENT√âE : GESTION DE L'ERREUR (Option 1)
--------------------------------------------------------
Date : 22 Janvier 2026

MODIFICATIONS DANS orchestrator.py :
1. Import de `openai` pour capturer BadRequestError
2. Try/catch dans _executor_node() pour d√©tecter "context_length_exceeded"
3. Si d√©tect√© : cr√©ation d'un message EXPLORATION_COMPLETE + flag context_exceeded
4. Le summarizer ajoute un avertissement "‚ö†Ô∏è R√©sultats partiels" si n√©cessaire
5. Ajout du champ `context_exceeded: bool` dans GraphState

R√âSULTAT DU TEST :
- Requ√™te : "Quels investisseurs ont investi dans Twitter entre 2008 et 2012?"
- Avant : Crash apr√®s 53 it√©rations (erreur OpenAI)
- Apr√®s : Arr√™t propre √† l'it√©ration 95 + r√©sum√© partiel retourn√©

COMPORTEMENT :
```
üîß [Ex√©cuteur] It√©ration 95...
‚ö†Ô∏è  [Ex√©cuteur] Contexte trop grand - passage au r√©sum√© avec les r√©sultats partiels...
üìù [Summarizer] Production du r√©sum√© final...
‚ö†Ô∏è **R√©sultats partiels** (exploration interrompue)
[... r√©sum√© ...]
```

================================================================================
                              FIN DE L'HISTORIQUE
================================================================================
