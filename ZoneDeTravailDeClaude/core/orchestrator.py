"""
Orchestrateur LangGraph - Coordonne les agents et les outils pour rÃ©pondre aux requÃªtes.
C'est le coeur du systÃ¨me multi-agents.
"""

import json
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from agents.planner import PlannerAgent
from agents.prioritizer import PrioritizerAgent
from agents.summarizer import SummarizerAgent
from tools.elasticsearch_tools import TOOLS, get_es_tools


class GraphState(TypedDict):
    """Ã‰tat du graphe partagÃ© entre tous les noeuds."""
    # RequÃªte initiale
    query: str
    # Plan d'action gÃ©nÃ©rÃ©
    plan: str
    # RÃ©sultats d'exploration accumulÃ©s
    exploration_results: list[dict]
    # Noeuds explorÃ©s (pour Ã©viter les boucles)
    explored_nodes: list[dict]
    # Noeuds candidats Ã  explorer
    candidate_nodes: list[dict]
    # Compteur d'itÃ©rations (pour Ã©viter boucles infinies)
    iteration: int
    # RÃ©sumÃ© final
    summary: str
    # Messages pour le LLM exÃ©cuteur
    messages: Annotated[list, add_messages]
    # Flag de fin
    finished: bool


class GraphOrchestrator:
    """
    Orchestrateur principal utilisant LangGraph.
    Coordonne le Planificateur, l'ExÃ©cuteur (avec outils), le Priorisation et le Summarizer.
    """

    MAX_ITERATIONS = 10  # Limite de sÃ©curitÃ©

    def __init__(self, model_name: str = "gpt-4o-mini"):
        self.model_name = model_name

        # Initialiser les agents
        self.planner = PlannerAgent(model_name=model_name)
        self.prioritizer = PrioritizerAgent(model_name=model_name)
        self.summarizer = SummarizerAgent(model_name=model_name)

        # LLM exÃ©cuteur avec outils
        self.executor_llm = ChatOpenAI(model=model_name, temperature=0.0)
        self.executor_llm_with_tools = self.executor_llm.bind_tools(TOOLS)

        # Construire le graphe
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        """Construit le graphe LangGraph."""

        # CrÃ©er le graphe
        workflow = StateGraph(GraphState)

        # Ajouter les noeuds
        workflow.add_node("planner", self._plan_node)
        workflow.add_node("executor", self._executor_node)
        workflow.add_node("tools", ToolNode(TOOLS))
        workflow.add_node("prioritizer", self._prioritizer_node)
        workflow.add_node("summarizer", self._summarizer_node)

        # DÃ©finir le point d'entrÃ©e
        workflow.set_entry_point("planner")

        # Ajouter les transitions
        workflow.add_edge("planner", "executor")

        # AprÃ¨s executor: soit appeler tools, soit passer au prioritizer/summarizer
        workflow.add_conditional_edges(
            "executor",
            self._should_use_tools,
            {
                "tools": "tools",
                "prioritizer": "prioritizer",
                "summarizer": "summarizer"
            }
        )

        # AprÃ¨s tools: retourner Ã  executor
        workflow.add_edge("tools", "executor")

        # AprÃ¨s prioritizer: retourner Ã  executor ou terminer
        workflow.add_conditional_edges(
            "prioritizer",
            self._should_continue_exploration,
            {
                "executor": "executor",
                "summarizer": "summarizer"
            }
        )

        # Summarizer est la fin
        workflow.add_edge("summarizer", END)

        return workflow.compile()

    def _plan_node(self, state: GraphState) -> dict:
        """Noeud Planificateur - CrÃ©e le plan d'action."""
        print("\nğŸ“‹ [Planificateur] CrÃ©ation du plan d'action...")

        plan = self.planner.create_plan(state["query"])
        print(f"Plan crÃ©Ã©:\n{plan}\n")

        # PrÃ©parer le message systÃ¨me pour l'exÃ©cuteur
        system_message = SystemMessage(content=f"""Tu es un agent exÃ©cuteur qui suit un plan d'action pour explorer un graphe d'entreprises.

PLAN Ã€ SUIVRE:
{plan}

INSTRUCTIONS:
1. ExÃ©cute le plan Ã©tape par Ã©tape en utilisant les outils disponibles
2. AprÃ¨s chaque outil, analyse le rÃ©sultat
3. Adapte le plan si nÃ©cessaire (ex: si une entitÃ© n'est pas trouvÃ©e)
4. Quand le plan est complÃ©tÃ©, dis "EXPLORATION_COMPLETE"

Commence par la premiÃ¨re Ã©tape du plan.""")

        return {
            "plan": plan,
            "messages": [system_message],
            "iteration": 0,
            "exploration_results": [],
            "explored_nodes": [],
            "candidate_nodes": [],
            "finished": False
        }

    def _executor_node(self, state: GraphState) -> dict:
        """Noeud ExÃ©cuteur - ExÃ©cute le plan en utilisant les outils."""
        print(f"\nğŸ”§ [ExÃ©cuteur] ItÃ©ration {state['iteration'] + 1}...")

        # Appeler le LLM avec les outils
        response = self.executor_llm_with_tools.invoke(state["messages"])

        return {
            "messages": [response],
            "iteration": state["iteration"] + 1
        }

    def _should_use_tools(self, state: GraphState) -> str:
        """DÃ©cide si on doit appeler des outils ou passer Ã  la suite."""
        last_message = state["messages"][-1]

        # VÃ©rifier si le LLM veut utiliser des outils
        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            print("   â†’ Appel d'outils...")
            return "tools"

        # VÃ©rifier si l'exploration est terminÃ©e
        if "EXPLORATION_COMPLETE" in str(last_message.content):
            print("   â†’ Exploration terminÃ©e, passage au rÃ©sumÃ©...")
            return "summarizer"

        # VÃ©rifier la limite d'itÃ©rations
        if state["iteration"] >= self.MAX_ITERATIONS:
            print("   â†’ Limite d'itÃ©rations atteinte, passage au rÃ©sumÃ©...")
            return "summarizer"

        # Sinon, passer au prioritizer pour dÃ©cider de la suite
        print("   â†’ Passage au priorisation...")
        return "prioritizer"

    def _prioritizer_node(self, state: GraphState) -> dict:
        """Noeud Priorisation - DÃ©cide des prochains noeuds Ã  explorer."""
        print("\nğŸ¯ [Priorisation] Analyse des prochaines Ã©tapes...")

        # Extraire les rÃ©sultats actuels des messages
        results_summary = self._extract_results_summary(state["messages"])

        priorities = self.prioritizer.prioritize(
            objective=state["query"],
            explored_nodes=state["explored_nodes"],
            candidate_nodes=state["candidate_nodes"],
            partial_results=results_summary
        )

        print(f"PrioritÃ©s:\n{priorities}\n")

        # Ajouter les prioritÃ©s comme message pour l'exÃ©cuteur
        priority_message = HumanMessage(content=f"""Voici les noeuds prioritaires Ã  explorer:

{priorities}

Continue l'exploration ou dis "EXPLORATION_COMPLETE" si tu as assez d'informations.""")

        return {"messages": [priority_message]}

    def _should_continue_exploration(self, state: GraphState) -> str:
        """DÃ©cide si on continue l'exploration ou si on rÃ©sume."""
        # Simple heuristique: si on a dÃ©passÃ© un certain nombre d'itÃ©rations
        if state["iteration"] >= self.MAX_ITERATIONS // 2:
            return "summarizer"
        return "executor"

    def _summarizer_node(self, state: GraphState) -> dict:
        """Noeud Summarizer - Produit le rÃ©sumÃ© final."""
        print("\nğŸ“ [Summarizer] Production du rÃ©sumÃ© final...")

        # Extraire tous les rÃ©sultats des messages
        raw_results = self._extract_results_summary(state["messages"])

        summary = self.summarizer.summarize(
            original_query=state["query"],
            plan=state["plan"],
            raw_results=raw_results
        )

        return {"summary": summary, "finished": True}

    def _extract_results_summary(self, messages: list) -> str:
        """Extrait un rÃ©sumÃ© des rÃ©sultats Ã  partir des messages."""
        results = []
        for msg in messages:
            if hasattr(msg, "content") and msg.content:
                # Filtrer les messages systÃ¨me
                if isinstance(msg, (AIMessage, HumanMessage)):
                    content = str(msg.content)
                    if len(content) > 50:  # Ignorer les messages trÃ¨s courts
                        results.append(content[:500])  # Limiter la taille

        return "\n---\n".join(results[-10:])  # Garder les 10 derniers

    def run(self, query: str) -> str:
        """
        ExÃ©cute une requÃªte d'investigation.

        Args:
            query: La question de l'utilisateur en langage naturel

        Returns:
            Le rÃ©sumÃ© des rÃ©sultats
        """
        print(f"\n{'='*60}")
        print(f"ğŸ” Nouvelle investigation: {query}")
        print(f"{'='*60}")

        # Ã‰tat initial
        initial_state = {
            "query": query,
            "plan": "",
            "exploration_results": [],
            "explored_nodes": [],
            "candidate_nodes": [],
            "iteration": 0,
            "summary": "",
            "messages": [],
            "finished": False
        }

        # ExÃ©cuter le graphe
        final_state = self.graph.invoke(initial_state)

        return final_state.get("summary", "Aucun rÃ©sultat trouvÃ©.")
