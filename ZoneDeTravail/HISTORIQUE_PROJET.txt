================================================================================
           HISTORIQUE DU PROJET - SIREN Investigation Agent
                     Session du 21 Janvier 2026
================================================================================

1. CONTEXTE INITIAL
-------------------
- Entreprise : SIREN (graphes d'investigation)
- Objectif : Cr√©er un syst√®me multi-agents orchestr√© par LLM (OpenAI)
- Ancien projet : Trop complexe (9 agents, code non fonctionnel)
- Nouveau besoin : Fresh start avec 3 agents seulement

2. ARCHITECTURE CON√áUE
----------------------
Nous avons con√ßu une architecture simplifi√©e :

    Utilisateur (langage naturel)
           ‚îÇ
           ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     ORCHESTRATEUR (LangGraph)       ‚îÇ
    ‚îÇ                                     ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  ‚îÇPlanificateur‚îÇ ‚îÇPriorisation‚îÇ ‚îÇ  R√©sum√©   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                                     ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
    ‚îÇ  ‚îÇ   Outils IF (D√©terministes)    ‚îÇ‚îÇ
    ‚îÇ  ‚îÇ  lookup, get_neighbors, etc.   ‚îÇ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚ñº
      Elasticsearch (SIREN Investigate)

3. FICHIERS CR√â√âS
-----------------
/ZoneDeTravailDeClaude/
‚îú‚îÄ‚îÄ main.py                 ‚Üí Point d'entr√©e CLI
‚îú‚îÄ‚îÄ requirements.txt        ‚Üí D√©pendances Python
‚îú‚îÄ‚îÄ .env                    ‚Üí Configuration (cl√© OpenAI, Elasticsearch)
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ planner.py         ‚Üí Agent Planificateur
‚îÇ   ‚îú‚îÄ‚îÄ prioritizer.py     ‚Üí Agent Priorisation
‚îÇ   ‚îî‚îÄ‚îÄ summarizer.py      ‚Üí Agent R√©sum√©
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ elasticsearch_tools.py ‚Üí Outils IF (foraging)
‚îî‚îÄ‚îÄ core/
    ‚îî‚îÄ‚îÄ orchestrator.py    ‚Üí Orchestrateur LangGraph

4. PROBL√àME RENCONTR√â : BIBLIOTH√àQUE ELASTICSEARCH
--------------------------------------------------
ERREUR INITIALE :
    elasticsearch.ApiError: ApiError(500, 'security_exception', 'Not an SSL request')

DIAGNOSTIC :
- La biblioth√®que Python `elasticsearch` v9.x avait un probl√®me de connexion SSL
- Malgr√© les param√®tres verify_certs=False et ssl_show_warn=False,
  la biblioth√®que envoyait des requ√™tes HTTP au lieu de HTTPS
- Le serveur SIREN Elasticsearch attendait du HTTPS et rejetait les requ√™tes

TEST DE V√âRIFICATION :
- curl -k (avec HTTPS) fonctionnait parfaitement
- La biblioth√®que `requests` fonctionnait aussi
- Seule la biblioth√®que `elasticsearch` posait probl√®me

SOLUTION APPLIQU√âE :
- Remplacement de la biblioth√®que `elasticsearch` par `requests` directement
- Cr√©ation d'une m√©thode _search() qui utilise requests.post() avec verify=False
- R√©sultat : Connexion fonctionnelle !

CODE AVANT (ne fonctionnait pas) :
    from elasticsearch import Elasticsearch
    es = Elasticsearch("https://localhost:9220", verify_certs=False)
    es.search(...)  # ERREUR SSL

CODE APR√àS (fonctionne) :
    import requests
    response = requests.post(url, json=query, auth=auth, verify=False)
    response.json()  # OK !

5. AUTRE BUG CORRIG√â : NoneType dans get_neighbors
--------------------------------------------------
ERREUR :
    TypeError: 'NoneType' object is not iterable

CAUSE :
- Certains documents "investment" n'avaient pas de champ "investors"
- Le code faisait : inv.get("investors", []) mais retournait None au lieu de []

SOLUTION :
- Chang√© en : inv.get("investors") or []
- Cela g√®re le cas o√π le champ est None ou absent

6. TESTS R√âUSSIS
----------------
Requ√™te 1 : "Quels sont les investisseurs de MongoDB?"
‚Üí R√©sultat : MongoDB n'a pas d'investisseurs dans cette base demo

Requ√™te 2 : "Trouve les investisseurs d'Airbnb"
‚Üí R√©sultat : Keith Rabois, Y Combinator

Requ√™te 3 : "Trouve un lien entre Twitter et Airbnb"
‚Üí R√©sultat : 6 investisseurs communs trouv√©s !
   - Ron Conway
   - Tim Ferriss
   - Kleiner Perkins Caufield & Byers
   - T. Rowe Price
   - DFJ Growth
   - Union Square Ventures

7. SERVICES EN ARRI√àRE-PLAN
---------------------------
Elasticsearch et Siren Investigate ont √©t√© lanc√©s en arri√®re-plan.

Pour les arr√™ter :
    pkill -f elasticsearch
    pkill -f investigate

Pour les relancer :
    cd /home/pierre/T√©l√©chargements/siren-platform-demo-data-15.0.0-linux-x86_64/elasticsearch
    ./bin/elasticsearch &

    cd /home/pierre/T√©l√©chargements/siren-platform-demo-data-15.0.0-linux-x86_64/siren-investigate
    ./bin/investigate &

8. LIMITATION D√âCOUVERTE : D√âPASSEMENT DE CONTEXTE
---------------------------------------------------
ERREUR :
    openai.BadRequestError: context_length_exceeded (128068 tokens > 128000 max)

CAUSE :
- Requ√™tes complexes avec filtres temporels peuvent causer des boucles
- Le syst√®me a fait 53 it√©rations avant de d√©passer la limite
- Chaque it√©ration accumule des r√©sultats dans les messages

EXEMPLE QUI √âCHOUE :
    "Quels investisseurs ont investi dans Twitter entre 2008 et 2012?"

EXEMPLES QUI FONCTIONNENT :
    "Trouve les investisseurs d'Airbnb"
    "Trouve un lien entre Twitter et Airbnb"

AM√âLIORATIONS POSSIBLES (pour plus tard) :
- Tronquer les messages anciens pour rester sous la limite (Option 2)
- Ajouter une logique de compression/r√©sum√© interm√©diaire (Option 3)

9. SOLUTION IMPL√âMENT√âE : GESTION DE L'ERREUR (Option 1)
--------------------------------------------------------
Date : 22 Janvier 2026

MODIFICATIONS DANS orchestrator.py :
1. Import de `openai` pour capturer BadRequestError
2. Try/catch dans _executor_node() pour d√©tecter "context_length_exceeded"
3. Si d√©tect√© : cr√©ation d'un message EXPLORATION_COMPLETE + flag context_exceeded
4. Le summarizer ajoute un avertissement "‚ö†Ô∏è R√©sultats partiels" si n√©cessaire
5. Ajout du champ `context_exceeded: bool` dans GraphState

R√âSULTAT DU TEST :
- Requ√™te : "Quels investisseurs ont investi dans Twitter entre 2008 et 2012?"
- Avant : Crash apr√®s 53 it√©rations (erreur OpenAI)
- Apr√®s : Arr√™t propre √† l'it√©ration 95 + r√©sum√© partiel retourn√©

COMPORTEMENT :
```
üîß [Ex√©cuteur] It√©ration 95...
‚ö†Ô∏è  [Ex√©cuteur] Contexte trop grand - passage au r√©sum√© avec les r√©sultats partiels...
üìù [Summarizer] Production du r√©sum√© final...
‚ö†Ô∏è **R√©sultats partiels** (exploration interrompue)
[... r√©sum√© ...]
```

10. PREMI√àRE TENTATIVE : LIMITATION ARBITRAIRE (fausse Option 2)
-----------------------------------------------------------------
Date : 28 Janvier 2026

MODIFICATIONS INITIALES :
- MAX_ITEMS = 20 dans elasticsearch_tools.py
- MAX_MESSAGES = 20 dans orchestrator.py
- _truncate_messages_safely() pour pr√©server paires tool_calls/tool

PROBL√àME :
Ces modifications √©taient des LIMITATIONS ARBITRAIRES, pas une vraie optimisation.
On perdait potentiellement des donn√©es utiles.


11. VRAIE OPTION 2 : CONDENSATION INTELLIGENTE DU CONTEXTE
----------------------------------------------------------
Date : 29 Janvier 2026

OBJECTIF :
Optimiser le contexte en R√âSUMANT les d√©couvertes (pr√©server l'info)
au lieu de TRONQUER (perdre l'info).

MODIFICATIONS FINALES :

A) Dans elasticsearch_tools.py :
   - ESSENTIAL_FIELDS : garde seulement les champs utiles (vraie optimisation)
   - MAX_ITEMS = 50 (augment√© pour ne pas perdre d'info)

B) Dans orchestrator.py :
   - MAX_ITERATIONS = 15 (augment√© pour plus d'exploration)
   - CONDENSE_THRESHOLD = 25 (seuil pour d√©clencher condensation)
   - KEEP_RECENT_MESSAGES = 6 (messages r√©cents apr√®s condensation)

   Nouvelle m√©thode _condense_context() qui :
   1. Pr√©serve les paires tool_calls/tool (identifie les "unit√©s")
   2. Demande au LLM de R√âSUMER les d√©couvertes anciennes
   3. Remplace les vieux messages par : [SystemMsg, R√©sum√©, Messages r√©cents]
   4. Conserve l'information cl√© tout en r√©duisant les tokens

DIFF√âRENCE CL√â :
   - Fausse Option 2 : troncature ‚Üí perte d'information
   - Vraie Option 2 : condensation ‚Üí pr√©servation de l'information r√©sum√©e

R√âSULTATS DES TESTS :

Test 1 : "Quels investisseurs ont investi dans Twitter entre 2008 et 2012?"
   - 5 it√©rations (condensation non d√©clench√©e)
   - R√©sultats : Tim Ferriss, Union Square Ventures, T. Rowe Price

Test 2 : "Trouve tous les liens entre Airbnb, Twitter et Facebook"
   - 7 it√©rations (condensation non d√©clench√©e)
   - Plan en 10 √©tapes ex√©cut√© avec succ√®s
   - Investisseurs list√©s pour chaque entreprise

La condensation se d√©clenchera automatiquement si une exploration
d√©passe 25 messages, pr√©servant les d√©couvertes cl√©s.

12. BATTERIE DE TESTS ET CORRECTIONS MAJEURES
----------------------------------------------
Date : 29 Janvier 2026

PROBL√àMES IDENTIFI√âS PAR LES TESTS :

A) Le LLM utilisait mal get_neighbors :
   - Plan g√©n√©r√©: entity_type="investment" au lieu de "investor"
   - Cause: Documentation de l'outil pas assez claire

B) Les ToolMessages √©taient ignor√©s par le summarizer :
   - _extract_results_summary ne traitait que AIMessage et HumanMessage
   - Les donn√©es des outils (ToolMessage) √©taient perdues !

C) Troncature trop agressive :
   - content[:500] perdait la plupart des donn√©es
   - 38 entreprises r√©duites √† 2 dans le r√©sum√© final

CORRECTIONS APPORT√âES :

1. elasticsearch_tools.py - Docstring get_neighbors am√©lior√©e :
   - Tableau clair montrant quel entity_type utiliser
   - Exemples CORRECT et FAUX explicites
   - Format visuel plus lisible

2. agents/planner.py - Prompt enrichi :
   - Tableau explicatif pour get_neighbors
   - Instructions sur la correspondance entity_type/entity_id

3. orchestrator.py - _extract_results_summary r√©√©crit :
   - Inclut maintenant les ToolMessage
   - Nouvelle m√©thode _summarize_tool_data() pour extraction intelligente
   - Parse le JSON et extrait: labels, counts, montants
   - G√®re les gros r√©sultats sans tout tronquer

R√âSULTATS DES TESTS DE VALIDATION :

| Test                              | Avant     | Apr√®s      |
|-----------------------------------|-----------|------------|
| Kleiner Perkins ‚Üí companies       | 2/38      | 38/38 ‚úÖ   |
| Investisseurs de Twitter          | partiel   | 6/6 ‚úÖ     |
| Investissements Jeff Bezos        | non test√© | 4/4 ‚úÖ     |
| Investisseurs communs Google/Amazon| OK       | 0 (correct)‚úÖ|

13. AM√âLIORATION: FILTRAGE PAR ENTIT√â DANS find_investments_in_period
----------------------------------------------------------------------
Date : 29 Janvier 2026

PROBL√àME IDENTIFI√â :
La requ√™te "Combien d'investissements Facebook a re√ßu entre 2010 et 2020?"
retournait TOUS les investissements de la p√©riode (50), pas ceux de Facebook.

CAUSE :
`find_investments_in_period` n'avait pas de param√®tre pour filtrer par company
ou investor.

SOLUTION :
Ajout de deux nouveaux param√®tres √† `find_investments_in_period`:
- `company_id`: pour filtrer les investissements RE√áUS par une company
- `investor_id`: pour filtrer les investissements FAITS par un investor

MODIFICATIONS :
1. elasticsearch_tools.py:
   - M√©thode find_investments_in_period: ajout company_id et investor_id
   - Requ√™te ES: ajout de filtres "terms" sur companies[] et investors[]
   - Docstring @tool enrichie avec tableau d'exemples

2. agents/planner.py:
   - Prompt mis √† jour avec exemples d'utilisation des nouveaux param√®tres

TEST DE VALIDATION :
- Requ√™te: "Investissements re√ßus par Facebook 2010-2020"
- Avant: 50 investissements (TOUS), max 165M USD (FAUX)
- Apr√®s: 2 investissements, max 1.5 milliard USD (CORRECT ‚úÖ)

14. BATTERIE DE TESTS COMPL√àTE
------------------------------
Date : 29 Janvier 2026

OBJECTIF :
Valider le syst√®me multi-agents avec une batterie de 15 tests couvrant
tous les cas d'usage principaux et quelques pi√®ges.

CAT√âGORIES DE TESTS :
1. Recherche d'entit√©s (2 tests)
2. Liste d'investisseurs (2 tests)
3. Investissements par investisseur (2 tests)
4. Liens entre entit√©s (2 tests)
5. Filtres temporels (2 tests)
6. Requ√™tes complexes (2 tests)
7. Pi√®ges connaissances g√©n√©rales (3 tests)

R√âSULTATS :
- OK:      12/15 (80%)
- PARTIEL:  1/15 (7%)  - Test 6.2: timeout sur agr√©gation globale
- ECHEC:    1/15 (7%)  - Test 7.1: index "person" inexistant

NOTE GLOBALE : 83/100

POINTS FORTS VALID√âS :
+ Recherche d'entit√©s fiable
+ Navigation graphe (get_neighbors, find_common_investors)
+ Filtres temporels avec company_id/investor_id
+ Ne fabrique pas de donn√©es fictives
+ Indique clairement les absences de donn√©es

LIMITATIONS IDENTIFI√âES :
- Pas de validation des index dans le prompt (person n'existe pas)
- Requ√™tes d'agr√©gation globale non support√©es

FICHIER DE TESTS : TESTS_VALIDATION.txt

================================================================================
                              FIN DE L'HISTORIQUE
================================================================================
